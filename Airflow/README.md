> # Работа с данными в Airflow
Рыботы выполнены в Apache Airflow на развернутом кластере.

- job_1 - DAG, выводящий в логи контекст исполнения PythonOperator;
- job_2 - DAG, создающий локульную папку с помощью BashOperator;
- job_3 - DAG для генерации данных в локальную папку;
- job_4 - DAG для аггрегации данных и записи с партиционированием по дате;
- job_5 - DAG для записи агрегированных данных в PostgeSQL;
- job_6 - DAG для подсчета агрегатов с помощью Spark и загрузки результатов в PostgeSQL.