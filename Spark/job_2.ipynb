{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Сохранить один месяц данных из папки /datasets/marketplace в личную базу username.market_events, данные партиционировать по дате\n",
        "\n",
        "Посчитать посуточные аггрегаты для этих данных по категориям в таблицу event_types_daily с колонками: event_date, category_id, event_type, event_count, distinct_customer_count. Счёт нужно производить отдельно по дням (в цикле по датам), целевую таблицу тоже разделить на партици"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%spark.pyspark\n",
        "\n",
        "market_events = spark.read.csv(\"/datasets/marketplace/2019_oct_parts.csv\", header=True, inferSchema=True)\n",
        "market_events.show(n= 5, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Задание 1\n",
        "\n",
        "Сохранить один месяц данных из папки /datasets/marketplace/2019_oct_parts.csv в личную базу username.market_events, данные партиционировать по дате"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%spark.pyspark\n",
        "\n",
        "from pyspark.sql.functions import to_timestamp, col, to_date\n",
        "\n",
        "spark.sql(\"create database if not exists kruglov\")\n",
        "\n",
        "(\n",
        "market_events\n",
        ".withColumn(\"event_time\", to_timestamp(col(\"event_time\"), 'yyyy-MM-dd HH:mm:ss'))\n",
        ".withColumn(\"event_date\", to_date(col(\"event_time\")))\n",
        ".write\n",
        ".partitionBy(\"event_date\")\n",
        ".mode(\"overwrite\")\n",
        ".saveAsTable(\"kruglov.market_events\")\n",
        ")\n",
        "\n",
        "spark.table(\"kruglov.market_events\").show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Задание 2\n",
        "\n",
        "Посчитать посуточные аггрегаты для этих данных по категориям в таблицу event_types_daily с колонками: event_date, category_id, event_type, event_count, distinct_customer_count. Счёт нужно производить отдельно по дням (в цикле по датам), целевую таблицу тоже разделить на партиции."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%spark.pyspark\n",
        "\n",
        "\n",
        "from pyspark.sql.functions import count, countDistinct\n",
        "\n",
        "\n",
        "market_events = spark.table(\"kruglov.market_events\")\n",
        "\n",
        "for dates in market_events.select(\"event_date\").distinct().collect():\n",
        "    date = dates[0]\n",
        "    event_types_daily = market_events.filter(market_events.event_date == date) \\\n",
        "        .groupBy(\"event_date\", \"category_id\", \"event_type\") \\\n",
        "        .agg(count(\"event_type\").alias(\"event_count\"),\n",
        "             countDistinct(\"user_id\").alias(\"distinct_customer_count\"))\n",
        "\n",
        "    event_types_daily.write\\\n",
        "                     .partitionBy(\"event_date\")\\\n",
        "                     .mode(\"append\")\\\n",
        "                     .saveAsTable(\"kruglov.event_types_daily\")\n",
        "\n",
        "spark.table(\"kruglov.event_types_daily\").show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%spark.pyspark\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    },
    "name": "homework_2"
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
